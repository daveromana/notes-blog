
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>learn</title>
  <meta name="author" content="Ankit">

  
  <meta name="description" content="Source: https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt CGROUPS Control Groups provide a mechanism for aggregation/participating sets of &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://goyalankit.github.io/notes-blog/blog/4/">
  <link href="/notes-blog/favicon.png" rel="icon">
  <link href="/notes-blog/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
   <link href="/notes-blog/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <script src="/notes-blog/javascripts/modernizr-2.0.js"></script>
  <script src="/notes-blog/javascripts/ender.js"></script>
  <script src="/notes-blog/javascripts/octopress.js" type="text/javascript"></script>
  <link href="atom.xml" rel="alternate" title="learn" type="application/atom+xml">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

<!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href='http://fonts.googleapis.com/css?family=Lato:400,100,100italic,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Lora:400,400italic,700,700italic' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:200,300,400,500,600,700,900' rel='stylesheet' type='text/css'>




  

  </head>

<body   >
  <header role="banner"><hgroup>
</hgroup>

</header>
   <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:goyalankit.github.io/notes-blog" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/notes-blog/">Blog</a></li>
  <li><a href="/notes-blog/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/notes-blog/blog/2014/09/16/cgroup-basics/">Cgroup Basics</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-16T05:38:43+05:30" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Source: <a href="https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt">https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt</a></p>

<h1>CGROUPS</h1>

<p>Control <strong>Groups</strong> provide a mechanism for aggregation/participating sets of tasks, and all their future children, into hierarchical groups with specialized behaviour.</p>

<hr />

<h1>Definitions</h1>

<h3>cgroup</h3>

<p>A <strong>cgroup</strong> associates a set of tasks with a set of parameters for one or more subsystems.</p>

<table>
<thead>
<tr>
<th>Term              </th>
<th> Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Set of Tasks      </td>
<td> process ids</td>
</tr>
<tr>
<td>Set of parameters </td>
<td> 1 or 2 CPUs</td>
</tr>
<tr>
<td>Subsystem         </td>
<td> CPUSET, MEMORY % or nodes.</td>
</tr>
</tbody>
</table>


<hr />

<h3>subsystem</h3>

<p>A <strong>subsystem</strong> is a module that makes use of the task grouping facilities provided by cgroup to treat group of tasks in particular ways.</p>

<ul>
<li>c<code>**group**</code> provides the grouping of tasks with a set of parameters.</li>
</ul>


<p>A subsystem is typically a <code>"resource controller"</code> that schedules a resource or applies per-cgroup limits. But it may be anything that wants to act on a group of processes e.g. a virtualization subsystem.</p>

<h3>Hierarchy</h3>

<p>A <strong>hierarchy</strong> is a set of cgroups arranged in a tree, such that every task in the system is in exactly one of the cgroups in the hierarchy, and a set of subsystems; each sub-system has system specific state attached to each cgroup in the hierarchy. Each hierarchy has an instance of the cgroup virtual filesystem associated with it.</p>

<p>Rule 1. A single hierarchy can have one or more subsystems attached to it.</p>

<p>Example: You create a single hierarchy for memory and cpu. It&rsquo;s good if you have one to one mapping. You can have:</p>

<ol>
<li><code>/cg1</code>: 40% memory, 60% CPU</li>
<li><code>/cg2</code>: 60% memory, 40% CPU</li>
</ol>


<p><img src="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/images/RMG-rule1.png" width="500"></p>

<p>Rule 2: Any single subsystem (such as cpu) subsystem cannot be attached to more than one hierarchy if one of those hierarchies has a different subsystem attached to it already.</p>

<p><img src="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/images/RMG-rule2.png" width="500"></p>

<p>Rule 3: A task can belong to only one cgroup in a hierarchy. All tasks on a system by default are member of default cgroup of that hierarchy, which is known as root cgroup.</p>

<p><img src="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/images/RMG-rule3.png" width="500"></p>

<p>Rule 4: Any process that forks itself creates a child task. By default child task inherits the cgroup membership of its parent but can be moved to different cgroups as needed.</p>

<p><img src="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/images/RMG-rule4.png" width="500"></p>

<p>source: <a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-Relationships_Between_Subsystems_Hierarchies_Control_Groups_and_Tasks.html">https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-Relationships_Between_Subsystems_Hierarchies_Control_Groups_and_Tasks.html</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/notes-blog/blog/2014/09/12/precise-cache-miss-analysis/">Precise Miss Analysis for Program Transformation With Caches of Arbitrary Associativity</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-12T22:31:54+05:30" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Source</strong>: <a href="http://mrmgroup.cs.princeton.edu/papers/ghosh_asplos98.pdf">http://mrmgroup.cs.princeton.edu/papers/ghosh_asplos98.pdf</a> <br/>
<strong>Published</strong>: 1998</p>

<p>Currently the gap between memory and processor is addressed by compile- and programmer- applied optimizations like matrix blocking, data structure padding and other program transformations.</p>

<p>This paper defined a CME (cache miss equation framework) which expresses memory references and cache conflict behavious in terms of set of equations.</p>

<p>Two main approaches to automatically improve data locality for loop-oriented programs:</p>

<ol>
<li><strong>Loop nest restructuring</strong> - <em>includes</em> permutation, tiling (parition loop space into chunks), fusion are used to reorder access patterns. These transformation have usually considered capacity misses in the past, however there could be conflict misses which are difficult to identify and are highly sensitive to problem size and base addresses.</li>
<li><strong>data layout optimizations</strong> - padding to the data structures.</li>
</ol>


<hr />

<p>CMEs are a system of <strong>linear Diophantine equations</strong></p>

<p>Assumptions:</p>

<ul>
<li>Loops are assumed to be normalized, such that step value is 1.</li>
<li>Consider only perfectly nested loop and some imperfectly nested loop if they have one block between the nests.</li>
<li>Loops contain no conditional statements.</li>
<li>All load/store inside loop nest belong only to array.</li>
</ul>


<h3>Cache Miss Equations</h3>

<h4>Cold Cache Misses</h4>

<ol>
<li>Either the first access along the direction of vector.</li>
<li>accesses that have just crossed a memory line boundary along the direction of vector.</li>
</ol>


<h4>Replacement Miss Equations</h4>

<ol>
<li>Example: for an access stream - Ra, Rb, Ra. A conflict clearly occurs in direct mapped cache if Ra and Rb maps to same cache line.</li>
</ol>


<p>This happens:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Memory_Address_of_Ra = Memory_Address_of_Rb + n * Cache Size + Line_Size_Range</span></code></pre></td></tr></table></div></figure>


<p>Roughly a conflict occurs if memory addresses accessed differs by multiples of cache size.</p>

<p>In case of k-way set associative cache, a miss occurs if between consecutive access to a memory line, at least k other accesses occur to distinct memory lines that map to the same cache set.</p>

<h3>Algorithm</h3>

<ol>
<li>Find all reuse vectors along an iteration point.</li>
<li>Order all reuse vectors in lexicographical order.</li>
<li>Find potential conflict points: p = i - r</li>
<li>Solve CME equations for each reuse vector and the solution at a point could belong to cold miss or conflict miss.</li>
<li>If the solution satisfies cold miss equations, mark them as &ldquo;intermediate points&rdquo; otherwise it is a conflict miss.</li>
</ol>


<p><strong>Set-Associative Cache</strong></p>

<p>Each CME soluction can be summarized using a triple (i,j,n). n denotes the cache &ldquo;wrap-arounds&rdquo;, and same value of n indicates the conflict for same memory line.</p>

<p>For k-way associative cache, maintain a set of disctinct conflict points with same n and if the set size exceeds k, we have a conflict.</p>

<h3>Solutions to CMEs</h3>

<h4>Padding</h4>

<p>Find constraints on CMEs using cache base address, dimensions size so that no solution exists for CME. Decide padding based on those constraints.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/notes-blog/blog/2014/09/12/cache-basics/">Cache Basics</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-12T22:10:19+05:30" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Performance of CPU increase very fast, however memory is not involving as fast (not the latency nor bandwidth of the bus).</p>

<p>So we put in cache closer to the processor. Caches are small.
* Caches are faster because they are smaller.
* Speed of light limits the speed for larger memories.</p>

<h3>Locality</h3>

<p>Programs tend to use data and insturctions with addresses near or equal to those recently used.</p>

<h4>Temporal Locality</h4>

<ul>
<li>Recently referenced items are likely to be referenced again in the near future.</li>
<li>Replacement policy of cache.</li>
</ul>


<h4>Spatial Locality</h4>

<ul>
<li>Items with nearby addresses tend to be referenced close together in time.</li>
<li>Bring blocks of memory to the cache</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sum = 0
</span><span class='line'>for (i = 0; i &lt; n; i++) {
</span><span class='line'>  sum += a[i];
</span><span class='line'>}
</span><span class='line'>return sum;</span></code></pre></td></tr></table></div></figure>


<p>In the above program:</p>

<p>Date:</p>

<ul>
<li><strong>Spatial Locality</strong>: array accessed with stride-1 pattern</li>
<li><strong>Temporal Locality</strong>: sum referenced in each iteration</li>
</ul>


<p>Instructions:</p>

<ul>
<li><strong>Temporal</strong>: cycle through loop iteratively.</li>
<li><strong>Spatial</strong>: reference instructions in sequence.</li>
</ul>


<h4>Cache structure of core i7</h4>

<p><img src="/notes-blog/images/post-images/core-i7.png"/></p>

<h3>Cache Line or Block Size</h3>

<p>In a direct mapped cache, cache line is the number of bytes that you can store at a given index (can be extended to set associative)</p>

<p><img src="/notes-blog/images/post-images/cache-line.png"/></p>

<h3>Cache conflicts</h3>

<h4>Reads</h4>

<ol>
<li><strong>Cold(compulsory misses)</strong>: Occurs on first block of data.</li>
<li><strong>Conflict Miss</strong>: Occurs when cache is large enough but multiple data objects all map to the same slot. e.g. referring block 0, 8, 0, 8.</li>
<li><strong>Capacity Miss</strong>: Occurs when the set of active cache blocks is larger than the cache.</li>
</ol>


<h4>Writes</h4>

<ol>
<li>Data may be stored at multiple levels of memory. (copies are spread across levels)</li>
<li>On <strong>write-hit</strong> (write block is in cache)

<ul>
<li><strong>Write-through</strong>: Write immediately to memory</li>
<li><strong>Write-back</strong> (defer write to memory until the line is evicted): Set a dirty bit to indicate if line is different from memory or not.</li>
</ul>
</li>
<li>On <strong>write-miss</strong>:

<ul>
<li><strong>write-allocate</strong>: load into cache, update line in cache. Good if more write to location follows.</li>
<li><strong>no-write-allocate</strong>: just write immediately to memory.</li>
</ul>
</li>
<li>Typical Caches:

<ul>
<li>write-back + write-allocate</li>
<li>wite-through + no-write-allocate, occasionally in case of multiple processors.</li>
</ul>
</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/notes-blog/blog/2014/09/11/threads-and-i-slash-o-in-the-synthesis-kernel/">Threads and Input/Output in the Synthesis Kernel</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-11T08:52:42+05:30" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Source: <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3887">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3887</a>
Published: 1989</p>

<p>Synthesis operating system kernel combines several techniques to provide high performance, including kernel code synthesis, fine grain scheduling and optimistic synchronization.</p>

<p>Goals:
1. High performance
2. self-tuning capability to dynamic load and configuration changes
3. a simple, uniform and intuitive model of computation with a high-level interface</p>

<p>Two kind of objects supported by synthesis kernel: Threads and I/O</p>

<h3>Synthesis model of computation</h3>

<p>To support parallel and distributed computing, the threads of execution form a directed graph, in which the nodes are threads and the arcs are data flow channels.</p>

<p>Synthesis threads are threads of execution. Some threads never execute user-level code, but run entirely within kernel to provide additional concurrency for some kernel operations. Threads execute program in quaspace (quasi address space) which also stores data. Finally, I/O devices move data between threads including files and messages.</p>

<h4>No virtual memory in current implementation</h4>

<p>On one physical node, all the synthesis quaspaces are subspaces of one single address space. Kernel blanks out parts of address space that each quaspace is not supposed to see. Since they are part of same quaspace, it is easy to share memory by setting their address mappings.</p>

<h2>Kernel Code Synthesis</h2>

<ol>
<li>Factoring invariants: bypasses redundant computations.</li>
<li>The Collapsing layer method eliminates unnecessary procedure calls and context switches, both vertically for layered modules and horizontally for pipelined threads.</li>
<li>The executable data structure method shorten the data structure traversal time when DS is travelled always the same way.</li>
</ol>


<p>Synthesis kernel can be devided into a number of (collections of procedures and data). These collection of procedures are called - quajects that encapsulate hardware resources (provide interface to hardware through quajects). Important quajects include threads and I/O devices servers.</p>

<p>Threads (quajects, that encapsulate hardware) are abstraction of CPU. The device servers are abstraction of I/O devices. Except from threads, quajects consist only of procedures and data.</p>

<p>quajects don&rsquo;t support inheritance or any other feature, events such as interrupts start the threads that animate the quajects and do work.</p>

<p>Building blocks of quajects:</p>

<ol>
<li>monitors, queues and schedulers.</li>
<li>switches (equivalent to C switch statement, direct interrupts to the appropriate servie routines), pumps (contains thread that actively copies its input into its output.) and guages (counts events like procedure calls, data arrival and interrupts; used by scheduler).</li>
</ol>


<p>pumps connect passive producers to passive consumers.</p>

<h3>Queues</h3>

<p>Queue Type => Synchronous (blocks at empty or full) and Asynchronous(signals at those conditions) => dedicated (only 1 producer or consumer, omits synchronization) and optimistic queues (accepts queue insert and delete from multiple prod;cons;)</p>

<h3>Threads are created by <strong>Quaject Creator</strong> in 3 stages</h3>

<ol>
<li><strong>Allocation</strong> - allocate memory - for quaject and procedures.</li>
<li><strong>Factorization</strong> - uses factorizing invariants to substitute constants into quaject&rsquo;s code templates.</li>
<li><strong>Optimization</strong> - do peephole optimizations.</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># mnemonic
</span><span class='line'> -----\|\ -&gt; [  - - \ - | \]  -&gt; [ - - - c \ - c | ] -&gt; [ - - - - c - - c ]</span></code></pre></td></tr></table></div></figure>


<h3>Quaject Interfacer</h3>

<p>Starts the execution of existing quajects by installing (load procedures and data) them in invoking thread. 4 Stages:</p>

<ol>
<li>find connecting mechanism (queue, monitor, pump or a simple procedure call) from 1 quaject to another.</li>
<li>Factorization and Optimization (Run time).</li>
<li>Dynamic link stage stores synthesized code&rsquo;s entry points to the quajects.</li>
</ol>


<h3>Reducing Synchronization</h3>

<p>Three methods to reduce Synchronization:</p>

<ol>
<li>Code Isolation (synchronization avoidance) -> kernel synthesis to separate independent modification of DS. e.g., Thread Table Entry (lock global table -> change local tables)</li>
<li>Procedure Chaining ( &ldquo;&rdquo; ) -> serializes the execution of conflicting threads. Signal during interrupt handling could be dangerous, so chain the prodedure invoked by signal to the end of interrupt handler (replace the return address - effecient.)</li>
<li>Optimistic Synchronization - update without synchronization, test at the end - if something bad happened -> rollback and retry.</li>
</ol>


<h3>Optimistic Queues</h3>

<p>Queues are important since lot of functionality is implemented using queues. Four types - SP-SC, SP-MC, MP-SC, MP-MC</p>

<ul>
<li><p><strong>SP-SC</strong> - synchronization is only necessary when queue becomes empty or full. Usually busy wait.
Solution: update the pointer (Q-head for producer, Q-tail for consumer) at the very end. In later architectures, you may have to put memory fence to ensure store order.</p></li>
<li><p><strong>MP-SC</strong> - compare-and-swap instruction + retry loop.
Now producers claim the space first by incrementing the Qhead and if successful they start inserting the elements. Consumers can&rsquo;t trust the head now, so producers update flags corresponding to queue positions indicating if the element is valid.</p></li>
</ul>


<p>Compare and swap is atomic, so they update a local pointer and see if it&rsquo;s valid. If it&rsquo;s valid then they swap it with head. -> all other producers will see the updated head now while the current producer is inserting elements on claimed space.</p>

<h3>Threads</h3>

<p>The thread state is defined by TTE containing register save area, interrupt handlers, error traps and signal vectors; the address map tables, <strong>context-switch-in and out procedures</strong>.</p>

<p>Kernel generates some code for threads in a protected area - custom system calls, synthesized interrupt handlers such as for queue buffering, specialized eror trap handlers and thread calls (start, stop, etc.)</p>

<ul>
<li>Thread switches to supervisor mode while running kernel call instead of kernel server running it for the thread. Kernel quaspace is made accessible.</li>
</ul>


<p>Waiting queue is spread accross resources and waiting thread&rsquo;s unblocking procedure is chained to the end of interrupts handler.</p>

<h3>Context Switch</h3>

<ol>
<li><p>Switch only the part of context being used. (most of the processes don&rsquo;t use FP co-processor so don&rsquo;t save state [default synthesized code] until used[then resynthsize code]).</p></li>
<li><p>use executable data structures to minimize critical path. - No &ldquo;dispatcher&rdquo; - context-switch-out of 1 process contains jmp to context-switch-in for next process.</p></li>
</ol>


<h3>Signal</h3>

<p>Signal is an asynchronous software interrupt sent by a thread to another. Signal system call modifies a general area so that receiving thread can run the signal handler code in used mode.</p>

<h3>Scheduling</h3>

<p>Fine grained quanta to threads - based on &ldquo;need to execute&rdquo; determined by rate at with I/O data flows into and out of its quaspace.</p>

<p>Effective CPU = Quanta to thread / Quanta to all threads</p>

<p>priority -> assigning large quanta or placing in front of ready queue.</p>

<h3>I/O</h3>

<p>At boot time, kernel creates the servers for raw physical devices. A simple example pipelines the raw input from tty to filters. multiple filters may be applied during the process.</p>

<h3>Producer/Consumer in I/O</h3>

<p>Active producer - Passive Consumer (or vice versa). In case of SP-SC, a procedure call from consumer asking producer for data does the job.</p>

<p>For MP-SC or SP-MC, attach monitor at the multiple end resulting in MP-SC or SP-MC queues.</p>

<p>Passive producer - Passive Consumer -> xclock -> clock producer ready to produce time and clock displayer ready to display at all times. We use PUMP here that reads from one end and writes to another.</p>

<h3>Interrupt Handlers</h3>

<p>Each threads has its own synthesized interrupt handellers and system calls. Lot of interrupts can be handelled in current execution thread only so minimal saving of registers is required and it avoid a context switch. During short level interrupt, higher level interrupts may happend and those inerrupts are chained.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/notes-blog/blog/2014/09/10/file-system-continued/">File System Continued</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-10T02:26:30+05:30" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img src="http://i.imgur.com/ZXnlN2R.jpg?1" width="500"></p>

<p><strong>fsync</strong>: transfers (flushes) all modified in-code data of the file to the disk drive. The call blocks until the device reports that the transfer has completed.</p>

<p><strong>fdatasync</strong>: is similar to fsync but it doesn&rsquo;t flush modified metadata unless that metadata is needed in order to allow a subsequent data retrieval to be correctly handled</p>

<p>source: <a href="http://www.hackinglinuxexposed.com/articles/20030616.html">http://www.hackinglinuxexposed.com/articles/20030616.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>flock(fd, operation)
</span><span class='line'>    Locks or unlocks an entire file. Doesn't work on NFS mounted filesystems, unfortunately.
</span><span class='line'>    Available operations are
</span><span class='line'>
</span><span class='line'>    LOCK_SH   Create a shared lock
</span><span class='line'>    LOCK_EX   Create an exclusive lock
</span><span class='line'>    LOCK_UN   Release our lock
</span><span class='line'>    LOCK_NB   Don't block when setting the lock. Return an error if the action cannot be completed.
</span><span class='line'>
</span><span class='line'>lockf(fd, operation, offset)
</span><span class='line'>    Locks or unlocks the portion of the file after offset. Allows you to lock just trailing portions of the file,
</span><span class='line'>    if desired. lockf is just a front end for fcntl. Arguments:
</span><span class='line'>
</span><span class='line'>    F_LOCK    Create an exclusive lock
</span><span class='line'>    F_TLOCK   Create an exclusive lock or return an error immediately
</span><span class='line'>    F_ULOCK   Release our lock
</span><span class='line'>    F_TEST    Test if the file is locked by another process.[3]
</span><span class='line'>
</span><span class='line'>fcntl(fd, command, struct flock );
</span><span class='line'>    fcntl offers you the most locking control. The flock structure details the beginning and end of the segment to lock.
</span><span class='line'>    It has arguments analogous to those for lockf and can differentiate between read and write locks.
</span><span class='line'>    (fcntl can do other things too, such as setting the close on exec flag, duplicating a file descriptor, and more.)</span></code></pre></td></tr></table></div></figure>


<h2>Virtual File System</h2>

<h3>file lookup</h3>

<p><img src="http://i.imgur.com/xzBvOct.png?1" width="500"><br/>
source: Profession Linux Kernel Architecture, chapter 8</p>

<p>Symbolic links are directory enteries which doesn&rsquo;t contain any data but just a pointer to filename. A separate inode is used for each symbolic link. The data segment of inode contains a character string that gives the name of the link target.</p>

<p>File descriptors with introduction of multiple namespaces and linux containers can no more uniquely identify a file. A unique representation is provided by a special data structure (struct file).</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/notes-blog/blog/2014/09/10/verification-by-model-checking/">Verification by Model Checking</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-10T01:58:31+05:30" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Formal verification techniques can be thought of comprising of three parts:</p>

<ol>
<li>a <strong>framework for modelling systems</strong>, typically a description language.</li>
<li>a <strong>specific language</strong> for describing the properties of the world.</li>
<li>a <strong>verification method</strong> to establish whether the description of the system satisfies the specification.</li>
</ol>


<p>Approaches to method verification:</p>

<ol>
<li>Proof Based: Here the system description is a set of formulas <em>Γ</em> and specific language is another formula φ. The verification method consists of trying to find a proof that <em>Γ</em> |− φ.</li>
<li>Model Based: the system is represented by model M, specification is again by a formula φ and the verification method consists of computing whether a model M satisfies φ.</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/notes-blog/blog/2014/09/08/exokernel-notes/">Exokernel: An OS Architecture for Application-level Resource Management - Notes</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-08T02:04:49+05:30" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>source</strong>: <a href="http://research.cs.wisc.edu/areas/os/Qual/papers/exokernel.pdf">http://research.cs.wisc.edu/areas/os/Qual/papers/exokernel.pdf</a><br/>
<strong>published</strong>: SIGOPS 1995</p>

<p>Traditionally operating systems define an interface between physical resources and applications. OS provides several abstractions like processes, files, address spaces and interprocess communication.</p>

<p><strong>These hardcoded abstractions limits</strong>:</p>

<ul>
<li>Domain specific optimizations</li>
<li>Discourages chages to the implementatinos of current abstractions</li>
<li>makes it difficult or impossible the applications to define new abstractions</li>
</ul>


<p>In exokernel these problems are solved by using <strong>application level (i.e., untrused) resource management</strong>. In exokernels, virtual memory and interprocess communication are implemented at application level. A minimal OS - <em>exokernel</em> basically multiplexes available hardware resource. These application level implementations are provided as libraries which application developers can directly or implement their own. Exokernel tries to implement a very low level interface, thus leaving a lattitude for more domain specific optimizations at the higher (application) level.</p>

<p>Exokernel rather than emulating hardware (virtual machines, high overhead), <em>exports</em> hardware resources. It employs three techniques to export resources securly:</p>

<ol>
<li><strong>secure bindings</strong>: applications can securely bind to machine resources and handle events.</li>
<li><strong>visible revocation</strong>: applications participate in a resource revocation protocol</li>
<li><strong>abort protocol</strong>: an exokernel can break secure bindings of uncooperative applications by force.</li>
</ol>


<p><strong>use cases of exokernels</strong>:</p>

<ol>
<li>Page tables are application dependent and using domain specific implementation each application may implement their own page tables in exokernel. For example in database implementation.</li>
<li>The same is true for cache replacement policy, a paper shows that application runtime can be improved by 45% by implementing application specific caching policies.</li>
<li>End-to-end arguments applies to exokernels and new tecchnology can be more easily adapted by providing library operating systems (application level resource management libraries).</li>
</ol>


<p><img src="http://i.imgur.com/wv54Rtd.png"></p>

<h3>Library Operating Systems</h3>

<ol>
<li>Library operating systems need not multiplex a resource so they can be easuly specialized without consideration of resource management.</li>
<li>Since lib OSs are treated as untrusted applications by exokernel , lib OS can trust the applications (which makes them easy to design). In case of invalid params to lib OS, exokernel will check the input (since untrusted) and declare it as invalid. No other applications will be effected.</li>
<li>Finally there will be less kernel crossings since most the OS runs in address space of applications.</li>
</ol>


<h3>Exokernel Design</h3>

<blockquote><p>The challenge of exokernel is to provide maximum freedom to applications in managing physical resource while protecting them form each other. Exokernel separates protection from management through low level interface</p></blockquote>

<h3>Exokernel Notes</h3>

<p>Deadlock conditions:
* mutual exclusion
* non-preemptive
* &mdash;
* &mdash;</p>

<p>Thrashing vs Livelock</p>

<p>End-to-end argument: putting reliability in your system, when you have end-to-end reliability checking can only be viewed as optimization.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="5">&larr; Older</a>
    
    <a href="/notes-blog/blog/archives/"> Archives </a>
    
    <a class="next" href="3">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section id="titles">
  <a href="http://goyalankit.github.io/notes-blog" title="learn"><img id="logo" src="http://goyalankit.github.io/notes-blog/images/logo.png" /></a>
  <h1 id="site_title"><a href="http://goyalankit.github.io/notes-blog" title="learn">learn</a></h1>
  <h3 id="site_subtitle">just code</h3>
</section>

<section id="menu">
  <ul>
    <li><i class="fa fa-home fa-lg"></i><a href="http://goyalankit.github.io/notes-blog"> Home </a></li>
    <li><i class="fa fa-calendar fa-lg"></i><a href="http://goyalankit.github.io/notes-blog/blog/archives/"> Archives </a></li>
    <li><i class="fa fa-user fa-lg"></i><a href="http://goyalankit.github.io/notes-blog/about/"> About </a></li>
    <li><i class="fa fa-rss fa-lg"></i><a href="http://goyalankit.github.io/notes-blog/atom.xml"> Feed </a></li>
  </ul>
</section>

<section id="social">
  

  

  

  
    <a href="https://github.com/goyalankit" title="goyalankit"><i class="fa fa-github fa-2x"></i></a>
  

  

  
    <a href="https://twitter.com/_goyalankit" title="_goyalankit"><i class="fa fa-twitter fa-2x"></i></a>
  
</section>


<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/notes-blog/blog/2014/11/18/concurrent-objects/">Concurrent Objects</a>
      </li>
    
      <li class="post">
        <a href="/notes-blog/blog/2014/11/13/papi-native-hardware-counters/">Papi native hardware counters</a>
      </li>
    
      <li class="post">
        <a href="/notes-blog/blog/2014/11/12/fast-paxos/">Fast Paxos</a>
      </li>
    
      <li class="post">
        <a href="/notes-blog/blog/2014/11/07/ruby-notes/">Ruby Notes</a>
      </li>
    
      <li class="post">
        <a href="/notes-blog/blog/2014/11/07/spanner-googles-globally-distributed-database/">Spanner: Google&#8217;s Globally Distributed Database</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/goyalankit">@goyalankit</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'goyalankit',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/notes-blog/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Ankit -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'goyalankit';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
