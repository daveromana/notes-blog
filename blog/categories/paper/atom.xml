<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: paper | learn]]></title>
  <link href="http://goyalankit.github.io/notes-blog/blog/categories/paper/atom.xml" rel="self"/>
  <link href="http://goyalankit.github.io/notes-blog/"/>
  <updated>2015-01-01T02:19:53+05:30</updated>
  <id>http://goyalankit.github.io/notes-blog/</id>
  <author>
    <name><![CDATA[Ankit]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Threads and Input/Output in the Synthesis Kernel]]></title>
    <link href="http://goyalankit.github.io/notes-blog/blog/2014/09/11/threads-and-i-slash-o-in-the-synthesis-kernel/"/>
    <updated>2014-09-11T08:52:42+05:30</updated>
    <id>http://goyalankit.github.io/notes-blog/blog/2014/09/11/threads-and-i-slash-o-in-the-synthesis-kernel</id>
    <content type="html"><![CDATA[<p>Source: <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3887">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3887</a>
Published: 1989</p>

<p>Synthesis operating system kernel combines several techniques to provide high performance, including kernel code synthesis, fine grain scheduling and optimistic synchronization.</p>

<p>Goals:
1. High performance
2. self-tuning capability to dynamic load and configuration changes
3. a simple, uniform and intuitive model of computation with a high-level interface</p>

<p>Two kind of objects supported by synthesis kernel: Threads and I/O</p>

<h3>Synthesis model of computation</h3>

<p>To support parallel and distributed computing, the threads of execution form a directed graph, in which the nodes are threads and the arcs are data flow channels.</p>

<p>Synthesis threads are threads of execution. Some threads never execute user-level code, but run entirely within kernel to provide additional concurrency for some kernel operations. Threads execute program in quaspace (quasi address space) which also stores data. Finally, I/O devices move data between threads including files and messages.</p>

<h4>No virtual memory in current implementation</h4>

<p>On one physical node, all the synthesis quaspaces are subspaces of one single address space. Kernel blanks out parts of address space that each quaspace is not supposed to see. Since they are part of same quaspace, it is easy to share memory by setting their address mappings.</p>

<h2>Kernel Code Synthesis</h2>

<ol>
<li>Factoring invariants: bypasses redundant computations.</li>
<li>The Collapsing layer method eliminates unnecessary procedure calls and context switches, both vertically for layered modules and horizontally for pipelined threads.</li>
<li>The executable data structure method shorten the data structure traversal time when DS is travelled always the same way.</li>
</ol>


<p>Synthesis kernel can be devided into a number of (collections of procedures and data). These collection of procedures are called - quajects that encapsulate hardware resources (provide interface to hardware through quajects). Important quajects include threads and I/O devices servers.</p>

<p>Threads (quajects, that encapsulate hardware) are abstraction of CPU. The device servers are abstraction of I/O devices. Except from threads, quajects consist only of procedures and data.</p>

<p>quajects don&rsquo;t support inheritance or any other feature, events such as interrupts start the threads that animate the quajects and do work.</p>

<p>Building blocks of quajects:</p>

<ol>
<li>monitors, queues and schedulers.</li>
<li>switches (equivalent to C switch statement, direct interrupts to the appropriate servie routines), pumps (contains thread that actively copies its input into its output.) and guages (counts events like procedure calls, data arrival and interrupts; used by scheduler).</li>
</ol>


<p>pumps connect passive producers to passive consumers.</p>

<h3>Queues</h3>

<p>Queue Type => Synchronous (blocks at empty or full) and Asynchronous(signals at those conditions) => dedicated (only 1 producer or consumer, omits synchronization) and optimistic queues (accepts queue insert and delete from multiple prod;cons;)</p>

<h3>Threads are created by <strong>Quaject Creator</strong> in 3 stages</h3>

<ol>
<li><strong>Allocation</strong> - allocate memory - for quaject and procedures.</li>
<li><strong>Factorization</strong> - uses factorizing invariants to substitute constants into quaject&rsquo;s code templates.</li>
<li><strong>Optimization</strong> - do peephole optimizations.</li>
</ol>


<pre><code># mnemonic
 -----\|\ -&gt; [  - - \ - | \]  -&gt; [ - - - c \ - c | ] -&gt; [ - - - - c - - c ]
</code></pre>

<h3>Quaject Interfacer</h3>

<p>Starts the execution of existing quajects by installing (load procedures and data) them in invoking thread. 4 Stages:</p>

<ol>
<li>find connecting mechanism (queue, monitor, pump or a simple procedure call) from 1 quaject to another.</li>
<li>Factorization and Optimization (Run time).</li>
<li>Dynamic link stage stores synthesized code&rsquo;s entry points to the quajects.</li>
</ol>


<h3>Reducing Synchronization</h3>

<p>Three methods to reduce Synchronization:</p>

<ol>
<li>Code Isolation (synchronization avoidance) -> kernel synthesis to separate independent modification of DS. e.g., Thread Table Entry (lock global table -> change local tables)</li>
<li>Procedure Chaining ( &ldquo;&rdquo; ) -> serializes the execution of conflicting threads. Signal during interrupt handling could be dangerous, so chain the prodedure invoked by signal to the end of interrupt handler (replace the return address - effecient.)</li>
<li>Optimistic Synchronization - update without synchronization, test at the end - if something bad happened -> rollback and retry.</li>
</ol>


<h3>Optimistic Queues</h3>

<p>Queues are important since lot of functionality is implemented using queues. Four types - SP-SC, SP-MC, MP-SC, MP-MC</p>

<ul>
<li><p><strong>SP-SC</strong> - synchronization is only necessary when queue becomes empty or full. Usually busy wait.
Solution: update the pointer (Q-head for producer, Q-tail for consumer) at the very end. In later architectures, you may have to put memory fence to ensure store order.</p></li>
<li><p><strong>MP-SC</strong> - compare-and-swap instruction + retry loop.
Now producers claim the space first by incrementing the Qhead and if successful they start inserting the elements. Consumers can&rsquo;t trust the head now, so producers update flags corresponding to queue positions indicating if the element is valid.</p></li>
</ul>


<p>Compare and swap is atomic, so they update a local pointer and see if it&rsquo;s valid. If it&rsquo;s valid then they swap it with head. -> all other producers will see the updated head now while the current producer is inserting elements on claimed space.</p>

<h3>Threads</h3>

<p>The thread state is defined by TTE containing register save area, interrupt handlers, error traps and signal vectors; the address map tables, <strong>context-switch-in and out procedures</strong>.</p>

<p>Kernel generates some code for threads in a protected area - custom system calls, synthesized interrupt handlers such as for queue buffering, specialized eror trap handlers and thread calls (start, stop, etc.)</p>

<ul>
<li>Thread switches to supervisor mode while running kernel call instead of kernel server running it for the thread. Kernel quaspace is made accessible.</li>
</ul>


<p>Waiting queue is spread accross resources and waiting thread&rsquo;s unblocking procedure is chained to the end of interrupts handler.</p>

<h3>Context Switch</h3>

<ol>
<li><p>Switch only the part of context being used. (most of the processes don&rsquo;t use FP co-processor so don&rsquo;t save state [default synthesized code] until used[then resynthsize code]).</p></li>
<li><p>use executable data structures to minimize critical path. - No &ldquo;dispatcher&rdquo; - context-switch-out of 1 process contains jmp to context-switch-in for next process.</p></li>
</ol>


<h3>Signal</h3>

<p>Signal is an asynchronous software interrupt sent by a thread to another. Signal system call modifies a general area so that receiving thread can run the signal handler code in used mode.</p>

<h3>Scheduling</h3>

<p>Fine grained quanta to threads - based on &ldquo;need to execute&rdquo; determined by rate at with I/O data flows into and out of its quaspace.</p>

<p>Effective CPU = Quanta to thread / Quanta to all threads</p>

<p>priority -> assigning large quanta or placing in front of ready queue.</p>

<h3>I/O</h3>

<p>At boot time, kernel creates the servers for raw physical devices. A simple example pipelines the raw input from tty to filters. multiple filters may be applied during the process.</p>

<h3>Producer/Consumer in I/O</h3>

<p>Active producer - Passive Consumer (or vice versa). In case of SP-SC, a procedure call from consumer asking producer for data does the job.</p>

<p>For MP-SC or SP-MC, attach monitor at the multiple end resulting in MP-SC or SP-MC queues.</p>

<p>Passive producer - Passive Consumer -> xclock -> clock producer ready to produce time and clock displayer ready to display at all times. We use PUMP here that reads from one end and writes to another.</p>

<h3>Interrupt Handlers</h3>

<p>Each threads has its own synthesized interrupt handellers and system calls. Lot of interrupts can be handelled in current execution thread only so minimal saving of registers is required and it avoid a context switch. During short level interrupt, higher level interrupts may happend and those inerrupts are chained.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Exokernel: an OS architecture for application-level resource management - Notes]]></title>
    <link href="http://goyalankit.github.io/notes-blog/blog/2014/09/08/exokernel-notes/"/>
    <updated>2014-09-08T02:04:49+05:30</updated>
    <id>http://goyalankit.github.io/notes-blog/blog/2014/09/08/exokernel-notes</id>
    <content type="html"><![CDATA[<p><strong>source</strong>: <a href="http://research.cs.wisc.edu/areas/os/Qual/papers/exokernel.pdf">http://research.cs.wisc.edu/areas/os/Qual/papers/exokernel.pdf</a><br/>
<strong>published</strong>: SIGOPS 1995</p>

<p>Traditionally operating systems define an interface between physical resources and applications. OS provides several abstractions like processes, files, address spaces and interprocess communication.</p>

<p><strong>These hardcoded abstractions limits</strong>:</p>

<ul>
<li>Domain specific optimizations</li>
<li>Discourages chages to the implementatinos of current abstractions</li>
<li>makes it difficult or impossible the applications to define new abstractions</li>
</ul>


<p>In exokernel these problems are solved by using <strong>application level (i.e., untrused) resource management</strong>. In exokernels, virtual memory and interprocess communication are implemented at application level. A minimal OS - <em>exokernel</em> basically multiplexes available hardware resource. These application level implementations are provided as libraries which application developers can directly or implement their own. Exokernel tries to implement a very low level interface, thus leaving a lattitude for more domain specific optimizations at the higher (application) level.</p>

<p>Exokernel rather than emulating hardware (virtual machines, high overhead), <em>exports</em> hardware resources. It employs three techniques to export resources securly:</p>

<ol>
<li><strong>secure bindings</strong>: applications can securely bind to machine resources and handle events.</li>
<li><strong>visible revocation</strong>: applications participate in a resource revocation protocol</li>
<li><strong>abort protocol</strong>: an exokernel can break secure bindings of uncooperative applications by force.</li>
</ol>


<p><strong>use cases of exokernels</strong>:</p>

<ol>
<li>Page tables are application dependent and using domain specific implementation each application may implement their own page tables in exokernel. For example in database implementation.</li>
<li>The same is true for cache replacement policy, a paper shows that application runtime can be improved by 45% by implementing application specific caching policies.</li>
<li>End-to-end arguments applies to exokernels and new tecchnology can be more easily adapted by providing library operating systems (application level resource management libraries).</li>
</ol>


<p><img class="<a" src="href="http://i.imgur.com/wv54Rtd.png">http://i.imgur.com/wv54Rtd.png</a>&#8221;></p>

<h3>Library Operating Systems</h3>

<ol>
<li>Library operating systems need not multiplex a resource so they can be easuly specialized without consideration of resource management.</li>
<li>Since lib OSs are treated as untrusted applications by exokernel , lib OS can trust the applications (which makes them easy to design). In case of invalid params to lib OS, exokernel will check the input (since untrusted) and declare it as invalid. No other applications will be effected.</li>
<li>Finally there will be less kernel crossings since most the OS runs in address space of applications.</li>
</ol>


<h3>Exokernel Design</h3>

<blockquote><p>The challenge of exokernel is to provide maximum freedom to applications in managing physical resource while protecting them form each other. Exokernel separates protection from management through low level interface</p></blockquote>

<h3>Exokernel Notes</h3>

<p>Deadlock conditions:
* mutual exclusion
* non-preemptive
* &mdash;
* &mdash;</p>

<p>Thrashing vs Livelock</p>

<p>End-to-end argument: putting reliability in your system, when you have end-to-end reliability checking can only be viewed as optimization.</p>
]]></content>
  </entry>
  
</feed>
